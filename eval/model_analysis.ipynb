{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4f07868",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipassynk/dating-match-fine-tuning/blob/main/eval/baseline_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743263f9",
      "metadata": {
        "id": "743263f9",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install sklearn\n",
        "!pip install umap\n",
        "!pip install hdbscan\n",
        "!pip install matplotlib\n",
        "!pip install plotly\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1871e86",
      "metadata": {
        "id": "a1871e86",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3018efbe",
      "metadata": {
        "id": "3018efbe",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def read_file(file_name):\n",
        "    positives = [];\n",
        "    negatives = [];\n",
        "\n",
        "    with open(file_name, 'r') as data:\n",
        "        lines = data.readlines()\n",
        "        for line in lines:\n",
        "            item = json.loads(line);\n",
        "            sentence1 = item['text_1'].split(': ')[1]\n",
        "            sentence2 = item['text_2'].split(': ')[1]\n",
        "            label = item['label']\n",
        "            el = {'sentence1': sentence1, 'sentence2': sentence2} # Corrected key for sentence2\n",
        "            if label == 1:\n",
        "                positives.append(el)\n",
        "            else:\n",
        "                negatives.append(el)\n",
        "    return  pd.DataFrame(positives), pd.DataFrame(negatives)\n",
        "\n",
        "def evaluate(model, type):\n",
        "\n",
        "    positives, negatives = read_file(\"dating_pairs.jsonl\");\n",
        "    print(positives.iloc[0])\n",
        "\n",
        "    sentences1 = [row['sentence1'] for index, row in positives.iterrows()];\n",
        "    sentences2 = [row['sentence2'] for index, row in positives.iterrows()];\n",
        "    embeddings1_positives = model.encode(sentences1, convert_to_numpy=True, show_progress_bar=True)\n",
        "    embeddings2_positives = model.encode(sentences2, convert_to_numpy=True, show_progress_bar=True)\n",
        "    similarity_positives_matrix = cosine_similarity(embeddings1_positives, embeddings2_positives)\n",
        "    similarity_positives = np.diag(similarity_positives_matrix)\n",
        "\n",
        "    sentences1 = [row['sentence1'] for index, row in negatives.iterrows()];\n",
        "    sentences2 = [row['sentence2'] for index, row in negatives.iterrows()];\n",
        "    embeddings1_negatives = model.encode(sentences1, convert_to_numpy=True, show_progress_bar=True)\n",
        "    embeddings2_negatives = model.encode(sentences2, convert_to_numpy=True, show_progress_bar=True)\n",
        "    similarity_negatives_matrix = cosine_similarity(embeddings1_negatives, embeddings2_negatives)\n",
        "    similarity_negatives = np.diag(similarity_negatives_matrix)\n",
        "\n",
        "    # t-test to check if the average similarity of sim_positive is significantly higher than that of sim_negative.\n",
        "    # Independent t-test\n",
        "    t_stat, p_value = stats.ttest_ind(similarity_positives, similarity_negatives)\n",
        "    print(\"t-statistic:\", t_stat)\n",
        "    print(\"p-value:\", p_value)\n",
        "\n",
        "    #Even if the difference is statistically significant, you also want to know how big it is. That’s what Cohen’s d measures:\n",
        "    def cohens_d(a, b):\n",
        "        mean_diff = np.mean(a) - np.mean(b)\n",
        "        pooled_std = np.sqrt((np.std(a, ddof=1)**2 + np.std(b, ddof=1)**2) / 2)\n",
        "         return mean_diff / pooled_std\n",
        "\n",
        "    cohen = cohens_d(similarity_positives, similarity_negatives)\n",
        "    print(\"Cohen's d:\", cohen)\n",
        "\n",
        "    #To calculate the Compatibility Margin, you use the difference between the average similarity of compatible pairs and incompatible pairs.\n",
        "I   #nterpretation\n",
        "    #Higher margin → better separation between compatible and incompatible pairs (model performs well).\n",
        "    #Smaller margin → overlap between groups (model struggles to distinguish them).\n",
        "    #Negative margin → incompatible pairs are more similar than compatible ones — indicates an issue.\n",
        "\n",
        "    def calculate_compatibility_margin(sim_positives, sim_negatives):\n",
        "        mean_compatible = np.mean(sim_positives)\n",
        "        mean_incompatible = np.mean(sim_negatives)\n",
        "        compatibility_margin = mean_compatible - mean_incompatible\n",
        "        return compatibility_margin\n",
        "\n",
        "    compatibility_margin = calculate_compatibility_margin(similarity_positives, similarity_negatives)\n",
        "    print(\"Compatibility Margin:\", compatibility_margin)\n",
        "\n",
        "    stat = {\n",
        "        'magin': float(compatibility_margin),\n",
        "        'p_value': float(p_value),\n",
        "        \"t-statistic\": float(t_stat),\n",
        "        'cohen': float(cohen)\n",
        "    }\n",
        "    open(\"{type}_stat.json\", \"w\").write(json.dumps(stat))\n",
        "    print(f\"{type} STAT\")\n",
        "    print(stat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4fabad",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_name ='all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(model_name)\n",
        "eval_model(model, 'base');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0250616a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_path ='model/dating_model'\n",
        "model = SentenceTransformer(model_path)\n",
        "eval_model(model, 'fine');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6039956f",
      "metadata": {
        "id": "6039956f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
